# ğŸ§® Semantic Search CLI â€“ Embeddings & Vector Similarity

A **productionâ€‘grade Semantic Search Command Line Interface** that demonstrates how modern AI systems retrieve relevant information using **text embeddings and vector similarity**.

This project represents the **retrieval layer of a RAG (Retrievalâ€‘Augmented Generation) system**:

```
Text â†’ Embeddings â†’ Similarity â†’ Ranking â†’ Retrieval
```

## ğŸ¯ Project Objectives

* Convert text into numerical embeddings
* Compare semantic similarity between texts
* Perform semantic search over a corpus
* Build and query a persistent vector index
* Benchmark embedding models
* Demonstrate performance characteristics

---

## ğŸ—ï¸ Project Structure

```
semantic-search/
â”‚
â”œâ”€â”€ semantic_search/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py      # Embedding generation
â”‚   â”œâ”€â”€ similarity.py      # Vector similarity math
â”‚   â”œâ”€â”€ compare.py         # Text comparison logic
â”‚   â”œâ”€â”€ search.py          # Non-indexed semantic search
â”‚   â””â”€â”€ index.py           # Vector index (build/search)
â”‚
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py            # CLI entry point
â”‚
â”œâ”€â”€ tests/
|   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_embeddings.py
â”‚   â”œâ”€â”€ test_similarity.py
â”‚   â”œâ”€â”€ test_compare.py
â”‚   â”œâ”€â”€ test_search.py
â”‚   â””â”€â”€ test_index.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus.txt         # Sample corpus
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Verify Setup

```bash
python -c "from fastembed import TextEmbedding; print('FastEmbed OK')"
```

---

## ğŸ§® CLI Commands & Usage

All commands are executed from the project root:

```bash
python -m cli.main <command> [options]
```

---

## 1ï¸âƒ£ Embed â€“ Generate Text Embeddings

### Single Text (with timing)

```bash
python -m cli.main embed "Machine learning is powerful" --model BAAI/bge-small-en-v1.5
```

**Output:**

* Embedding dimensions
* First 10 values
* Execution time

---

### Batch from File (with progress & timing)

```bash
python -m cli.main embed --file data/corpus.txt --model BAAI/bge-small-en-v1.5
```

**Output:**

* Number of texts
* Embedding matrix shape
* Progress bar
* Execution time

---

## 2ï¸âƒ£ Compare â€“ Compare Two Texts

```bash
python -m cli.main compare "I love Python" "I enjoy programming"
```

**Metrics Returned:**

* Cosine similarity
* Euclidean distance
* Dot product
* Humanâ€‘readable interpretation

---

## 3ï¸âƒ£ Semantic Search (Nonâ€‘Indexed)

```bash
python -m cli.main search "heart disease symptoms" data/corpus.txt
```

### Optional Threshold

```bash
python -m cli.main search "heart disease symptoms" data/corpus.txt --threshold 0.6
```

**Output:**

* Ranked results
* Similarity scores
* Search time

---

## 4ï¸âƒ£ Vector Index â€“ Build & Search

### Build Index (Persistent)

```bash
python -m cli.main index build data/corpus.txt --model BAAI/bge-small-en-v1.5
```

**Output:**

* Progress bar
* Document count
* Build time
* Saved index file (`index.npz`)

---

### Search Index

```bash
python -m cli.main index search "heart disease symptoms" --model BAAI/bge-small-en-v1.5
```

### With Threshold

```bash
python -m cli.main index search "heart disease symptoms" --threshold 0.6
```

**Output:**

* Ranked results
* Search time

> âš ï¸ Index enforces **model consistency**. Searching with a different model than the one used to build the index will raise a clear error.

---

## âš¡ 5ï¸âƒ£ Benchmark â€“ Model Comparison

```bash
python -m cli.main benchmark "I love Python" "I enjoy programming" --models "BAAI/bge-small-en-v1.5,BAAI/bge-base-en-v1.5"
```

**Output:**

* Cosine / Euclidean / Dot scores
* Execution time per model

---

## ğŸ§ª Testing

Run all tests:

```bash
pytest -v
```

Tests cover:

* Embedding correctness
* Similarity math
* Search ranking
* Index persistence
* Interpretation logic

---

---

## ğŸ³ Docker Usage (Run Anywhere)

This CLI is fully dockerized so it can run without installing Python locally.

### ğŸ“¦ Build Image

```bash
docker build -t semantic-search-cli .
```

---

### âš¡ Create Cache Folder (One Time on Host)

```bash
mkdir fastembed_cache
```

---

### â–¶ï¸ Embed

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface semantic-search-cli embed "Machine learning is powerful"
```

---

### ğŸ” Compare

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface semantic-search-cli compare "I love Python" "I enjoy programming"
```

---

### ğŸ“š Semantic Search

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface -v ${PWD}/data:/app/data semantic-search-cli search "machine learning models" data/corpus.txt
```

---

### ğŸ“¦ Index Build

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface -v ${PWD}/data:/app/data semantic-search-cli index build data/corpus.txt --output data/index.npz
```

---

### ğŸ” Index Search

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface -v ${PWD}/data:/app/data semantic-search-cli index search "machine learning models" --index data/index.npz
```

---

### âš¡ Benchmark

```bash
docker run --rm -v ${PWD}/fastembed_cache:/root/.cache/fastembed -v ${PWD}/fastembed_cache:/root/.cache/huggingface semantic-search-cli benchmark "I love Python" "I enjoy programming"
```

---

## ğŸ‘©â€ğŸ’» Author

**Aryika Patni**
